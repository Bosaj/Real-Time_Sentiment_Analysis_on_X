# Contenu de PrÃ©sentation Professionnelle
## Analyse de Sentiment en Temps RÃ©el sur les Flux X

---

## ğŸ“„ Slide 1 â€“ Page de garde

**Titre Principal:**
# Analyse de Sentiment en Temps RÃ©el sur les Flux X

**Sous-titre:**
Real-Time Sentiment Analysis on X Streams

**Domaine:**
Intelligence Artificielle | Big Data | Machine Learning | Streaming en Temps RÃ©el

**RÃ©alisÃ© par:**
- ELHADJI Oussama
- BEN ACHA Yassine
- CHAKOR Abdellatif
- MENACH Achraf

**AnnÃ©e:** 2024-2025

---

## ğŸ“„ Slide 2 â€“ Plan de PrÃ©sentation

**Titre:** Axes de la PrÃ©sentation

**DÃ©roulement de la soutenance :**

**I. Introduction**
- ğŸ“Œ Contexte gÃ©nÃ©ral et motivation
- ğŸ“Œ ProblÃ©matique identifiÃ©e
- ğŸ“Œ Objectifs et pÃ©rimÃ¨tre du projet

**II. Analyse et Conception**
- ğŸ“Œ Analyse fonctionnelle
- ğŸ“Œ Architecture globale du systÃ¨me
- ğŸ“Œ Description des donnÃ©es utilisÃ©es
- ğŸ“Œ MÃ©thodologie adoptÃ©e

**III. DÃ©veloppement et ImplÃ©mentation**
- ğŸ“Œ ModÃ¨les d'Intelligence Artificielle
- ğŸ“Œ Stack technologique
- ğŸ“Œ Architecture du code et organisation

**IV. RÃ©sultats et Validation**
- ğŸ“Œ RÃ©sultats quantitatifs et qualitatifs
- ğŸ“Œ Ã‰valuation et performances
- ğŸ“Œ DÃ©monstration de l'application

**V. Retour d'ExpÃ©rience**
- ğŸ“Œ DifficultÃ©s rencontrÃ©es et solutions
- ğŸ“Œ Perspectives et amÃ©liorations futures

**VI. Conclusion**
- ğŸ“Œ Bilan du projet
- ğŸ“Œ Questions & RÃ©ponses

---

## ğŸ“„ Slide 3 â€“ Contexte gÃ©nÃ©ral

**Titre:** Contexte et Motivation du Projet

**Contenu:**
- **Contexte acadÃ©mique :** Projet Big Data et Machine Learning
- **Ã‰volution des rÃ©seaux sociaux :** X gÃ©nÃ¨re des millions de tweets par jour
- **Besoin croissant :** Analyser en temps rÃ©el l'opinion publique sur des Ã©vÃ©nements, produits ou personnalitÃ©s
- **Applications pratiques :**
  - Veille stratÃ©gique pour les entreprises
  - DÃ©tection de tendances Ã©mergentes
  - Gestion de crise et e-rÃ©putation
  - Analyse marketing et comportementale
- **Enjeu technologique :** Traiter des flux massifs de donnÃ©es non structurÃ©es en temps rÃ©el

---

## ğŸ“„ Slide 4 â€“ ProblÃ©matique

**Titre:** ProblÃ©matique IdentifiÃ©e

**Contenu:**
- **ProblÃ¨me principal :** Comment analyser automatiquement le sentiment de milliers de tweets en temps rÃ©el ?

- **DÃ©fis techniques identifiÃ©s :**
  - Volume massif de donnÃ©es textuelles non structurÃ©es
  - Besoin de traitement en streaming (latence minimale)
  - HÃ©tÃ©rogÃ©nÃ©itÃ© du langage (argot, fautes, emojis, abrÃ©viations)
  - Classification multi-classes : Positif, NÃ©gatif, Neutre, Irrelevant

- **Limites des solutions traditionnelles :**
  - Traitement batch : temps de rÃ©ponse trop long
  - ModÃ¨les simples : faible prÃ©cision
  - Absence d'infrastructure scalable pour le temps rÃ©el

**Question centrale :** Comment concevoir un pipeline intelligent capable d'ingÃ©rer, traiter et classifier automatiquement des tweets en temps rÃ©el avec une haute prÃ©cision ?

---

## ğŸ“„ Slide 5 â€“ Objectifs du projet

**Titre:** Objectifs du Projet

**Objectif principal :**
DÃ©velopper une application web intelligente pour l'analyse automatique de sentiment en temps rÃ©el sur des flux X utilisant le Machine Learning et les technologies Big Data.

**Objectifs spÃ©cifiques :**
1. **Ingestion de donnÃ©es :** Capturer des flux X en temps rÃ©el via Apache Kafka
2. **PrÃ©traitement :** Nettoyer et transformer les donnÃ©es textuelles (tokenization, stop words removal)
3. **ModÃ©lisation ML :** EntraÃ®ner et optimiser des modÃ¨les de classification de sentiment
4. **PrÃ©diction temps rÃ©el :** Classifier chaque tweet en 4 catÃ©gories (Negative, Positive, Neutral, Irrelevant)
5. **Stockage intelligent :** Sauvegarder les rÃ©sultats dans une base MongoDB
6. **Visualisation :** CrÃ©er une interface web interactive pour monitorer les rÃ©sultats en temps rÃ©el
7. **ScalabilitÃ© :** Assurer la capacitÃ© de traiter des milliers de tweets/seconde

---

## ğŸ“„ Slide 6 â€“ PÃ©rimÃ¨tre du projet

**Titre:** PÃ©rimÃ¨tre du Projet

**Ce qui est INCLUS âœ…**
- Collecte de donnÃ©es X via fichiers CSV et simulation
- Pipeline de streaming temps rÃ©el avec Kafka et Spark
- EntraÃ®nement de modÃ¨les ML (Logistic Regression, Naive Bayes)
- Classification automatique en 4 classes de sentiment
- Interface web Flask pour visualisation et interaction
- Architecture conteneurisÃ©e avec Docker
- Stockage persistant dans MongoDB

**Ce qui est EXCLU âŒ**
- Connexion directe Ã  l'API X temps rÃ©el (utilisation de donnÃ©es simulÃ©es)
- Analyse multi-langues (focus sur l'anglais)
- Analyse d'images ou de vidÃ©os dans les tweets
- DÃ©tection de sarcasme ou d'ironie
- Analyse des mÃ©tadonnÃ©es utilisateur (localisation, followers, etc.)
- DÃ©ploiement en production sur cloud

---

## ğŸ“„ Slide 7 â€“ Analyse fonctionnelle

**Titre:** Analyse Fonctionnelle

**Acteurs du systÃ¨me :**
1. **Utilisateur final :** Analyste, marketeur, data scientist
2. **Producteur Kafka :** Simule l'ingestion de tweets
3. **Moteur Spark :** Traite et classifie les tweets
4. **Application Flask :** Interface utilisateur

**Cas d'utilisation principaux :**

| ID | Cas d'usage | Description |
|----|-------------|-------------|
| UC1 | Soumettre un tweet manuel | L'utilisateur saisit un texte et obtient le sentiment prÃ©dit |
| UC2 | Lancer le streaming | Diffuser automatiquement des tweets depuis le fichier de validation |
| UC3 | Visualiser les prÃ©dictions | Consulter en temps rÃ©el les rÃ©sultats d'analyse |
| UC4 | Consulter l'historique | AccÃ©der aux 50 derniÃ¨res prÃ©dictions stockÃ©es |
| UC5 | EntraÃ®ner le modÃ¨le | Lancer l'entraÃ®nement sur le dataset de formation |

**Flux principal :**
Ingestion â†’ PrÃ©traitement â†’ Feature Engineering â†’ PrÃ©diction â†’ Stockage â†’ Visualisation

---

## ğŸ“„ Slide 8 â€“ Architecture globale

**Titre:** Architecture Globale du SystÃ¨me

**Architecture en 4 couches :**

**1. Couche Ingestion (Data Source)**
- Fichiers CSV : `X_training.csv`, `X_validation.csv`
- Producteur Kafka : Envoie les tweets au topic `tweets`

**2. Couche Messaging (Stream Processing)**
- **Zookeeper** : Coordination des services Kafka
- **Apache Kafka** : Broker de messages pour streaming temps rÃ©el
- Topics : `tweets` (entrÃ©e des messages)

**3. Couche Traitement (Processing & ML)**
- **Apache Spark Streaming** : Consommation des messages Kafka
- **Spark MLlib** : Application du modÃ¨le de ML prÃ©-entraÃ®nÃ©
- Pipeline : Tokenization â†’ Stop Words Removal â†’ Hashing TF â†’ IDF â†’ PrÃ©diction

**4. Couche PrÃ©sentation & Stockage**
- **MongoDB** : Base NoSQL pour stockage des prÃ©dictions
- **Flask Application** : Interface web pour interaction et visualisation
- **API REST** : Endpoints pour produire/consommer des tweets

**Conteneurisation :**
- Docker Compose pour orchestration (Kafka, Zookeeper, MongoDB)

---

## ğŸ“„ Slide 9 â€“ DonnÃ©es utilisÃ©es

**Titre:** Description des DonnÃ©es

**Source principale :**
- **Dataset Kaggle :** X Entity Sentiment Analysis
- **Lien :** https://www.kaggle.com/datasets/jp797498e/X-entity-sentiment-analysis

**Fichiers de donnÃ©es :**

| Fichier | Utilisation | Taille | Nombre de lignes |
|---------|-------------|--------|------------------|
| `X_training.csv` | EntraÃ®nement du modÃ¨le | ~10 MB | ~74,000 tweets |
| `X_validation.csv` | Test temps rÃ©el | ~165 KB | ~1,000 tweets |

**Structure du dataset :**
```
Colonnes : [TweetID, Entity, Sentiment, Content]
- TweetID : Identifiant unique
- Entity : EntitÃ© mentionnÃ©e (produit, marque, personne)
- Sentiment : Label (Positive, Negative, Neutral, Irrelevant)
- Content : Texte du tweet
```

**PrÃ©traitement effectuÃ© :**
1. Nettoyage : suppression des valeurs nulles
2. Normalisation : conversion en minuscules
3. Suppression : balises HTML, URLs, chiffres, caractÃ¨res spÃ©ciaux
4. Tokenization : dÃ©coupage en mots
5. Filtrage : suppression des stop words (and, the, is, etc.)

---

## ğŸ“„ Slide 10 â€“ MÃ©thodologie

**Titre:** MÃ©thodologie AdoptÃ©e

**Approche globale :** Architecture Lambda adaptÃ©e pour le streaming temps rÃ©el

**Ã‰tapes du projet :**

**Phase 1 : PrÃ©paration des donnÃ©es**
1. Exploration et analyse du dataset Kaggle
2. Nettoyage et prÃ©traitement du texte
3. Feature engineering (TF-IDF)

**Phase 2 : DÃ©veloppement du modÃ¨le ML**
4. EntraÃ®nement de modÃ¨les avec Spark MLlib
5. Optimisation des hyperparamÃ¨tres (Grid Search + Cross-Validation)
6. Sauvegarde des modÃ¨les entraÃ®nÃ©s

**Phase 3 : Pipeline de streaming**
7. Configuration de l'infrastructure Kafka + Zookeeper
8. DÃ©veloppement du consumer Spark Streaming
9. IntÃ©gration du modÃ¨le ML dans le pipeline

**Phase 4 : Application web**
10. DÃ©veloppement de l'interface Flask
11. Connexion Ã  MongoDB pour stockage
12. API REST pour interaction utilisateur

**Phase 5 : Conteneurisation et dÃ©ploiement**
13. Dockerisation de l'environnement
14. Tests et validation end-to-end

---

## ğŸ“„ Slide 11 â€“ ModÃ¨les / Algorithmes

**Titre:** ModÃ¨les d'Intelligence Artificielle UtilisÃ©s

**ModÃ¨les entraÃ®nÃ©s :**

**1. Logistic Regression (RÃ©gression Logistique) âœ… ModÃ¨le retenu**
- **Type :** Classification multi-classes
- **HyperparamÃ¨tres optimisÃ©s :**
  - `regParam` : 0.01 (rÃ©gularisation)
  - `elasticNetParam` : 0.0 (L2 penalty)
  - `maxIter` : 10 (itÃ©rations)
- **Performance :** **86.64% d'accuracy**
- **Justification du choix :** Meilleure performance, bon Ã©quilibre biais-variance

**2. Naive Bayes (Classificateur bayÃ©sien naÃ¯f)**
- **Type :** Classification probabiliste
- **HyperparamÃ¨tres optimisÃ©s :**
  - `smoothing` : 1.0 (Laplace smoothing)
- **Performance :** **82.51% d'accuracy**
- **Avantages :** Rapide, efficace sur texte

**Optimisation :**
- **Technique :** Grid Search avec Cross-Validation (3-5 folds)
- **MÃ©trique :** Accuracy (prÃ©cision globale)

**Feature Engineering :**
- TF-IDF (Term Frequency - Inverse Document Frequency)
- Hashing TF : 262,144 features

---

## ğŸ“„ Slide 12 â€“ Outils et technologies

**Titre:** Stack Technologique

**Langages de programmation :**
- **Python 3.x** : Langage principal (ML, streaming, web)
- **JavaScript** : Frontend interactif
- **SQL** : RequÃªtes MongoDB

**Frameworks Big Data :**
- **Apache Spark 3.1.2** : Traitement distribuÃ©
- **Spark MLlib** : Machine Learning
- **Spark Structured Streaming** : Streaming temps rÃ©el

**Streaming & Messaging :**
- **Apache Kafka** : Broker de messages
- **Zookeeper** : Coordination de services

**Machine Learning & NLP :**
- **Scikit-learn concepts** : Classification
- **NLTK** : Natural Language Processing
- **Tokenizer, StopWordsRemover, HashingTF, IDF** (Spark ML)

**Web Development :**
- **Flask** : Framework web Python
- **HTML/CSS** : Interface utilisateur
- **Server-Sent Events (SSE)** : Streaming temps rÃ©el vers frontend

**Base de donnÃ©es :**
- **MongoDB** : Base NoSQL pour stockage des prÃ©dictions

**Conteneurisation :**
- **Docker & Docker Compose** : Orchestration des services

**BibliothÃ¨ques Python :**
- `pyspark`, `kafka-python`, `pymongo`, `pandas`, `flask`

---

## ğŸ“„ Slide 13 â€“ ImplÃ©mentation

**Titre:** Architecture du Code et Organisation

**Structure du projet :**
```
Real-Time_Sentiment_Analysis_on_X/
â”‚
â”œâ”€â”€ Application - FLASK/          # Application web
â”‚   â”œâ”€â”€ main.py                   # Serveur Flask
â”‚   â”œâ”€â”€ templates/                # Pages HTML
â”‚   â””â”€â”€ static/                   # CSS, JS
â”‚
â”œâ”€â”€ Spark/                        # Scripts Spark
â”‚   â”œâ”€â”€ Spark-MLlib.py           # EntraÃ®nement des modÃ¨les
â”‚   â”œâ”€â”€ KafkaSpark-Streaming.py  # Consumer Kafka + ML
â”‚   â”œâ”€â”€ Kafka-Streaming.py       # Alternative de streaming
â”‚   â”œâ”€â”€ X_training.csv     # Dataset d'entraÃ®nement
â”‚   â””â”€â”€ X_validation.csv   # Dataset de validation
â”‚
â”œâ”€â”€ docker-compose.yml            # Orchestration des services
â”œâ”€â”€ Dockerfile                    # Image Spark-Jupyter
â””â”€â”€ README.md                     # Documentation
```

**Pipeline technique :**

**1. EntraÃ®nement (`Spark-MLlib.py`) :**
```
Chargement CSV â†’ Tokenization â†’ Stop Words Removal â†’ 
HashingTF â†’ IDF â†’ StringIndexer â†’ 
Train/Test Split â†’ Grid Search + Cross-Validation â†’ 
Sauvegarde modÃ¨le (V1, IDF_V1)
```

**2. Streaming (`KafkaSpark-Streaming.py`) :**
```
Kafka Consumer â†’ DÃ©serialisation â†’ Preprocessing â†’ 
Feature Engineering â†’ PrÃ©diction ML â†’ 
Calcul confidence â†’ Sauvegarde MongoDB
```

**3. Application Web (`main.py`) :**
```
Endpoints Flask â†’ Kafka Producer â†’ 
MongoDB Monitoring (Change Stream) â†’ 
SSE pour streaming temps rÃ©el â†’ Visualisation
```

---

## ğŸ“„ Slide 14 â€“ RÃ©sultats obtenus

**Titre:** RÃ©sultats Quantitatifs et Qualitatifs

**Performances des modÃ¨les ML :**

| ModÃ¨le | Accuracy | Temps d'entraÃ®nement | ModÃ¨le retenu |
|--------|----------|---------------------|---------------|
| Logistic Regression | **86.64%** | ~2-3 min | âœ… Oui |
| Naive Bayes | **82.51%** | ~1-2 min | âŒ Non |

**RÃ©sultats quantitatifs :**
- **PrÃ©cision globale :** 86.64% sur le test set
- **Dataset de test :** ~15,000 tweets (20% du total)
- **Classes prÃ©dites :** 4 catÃ©gories (Positive, Negative, Neutral, Irrelevant)
- **Temps de prÃ©diction :** < 500ms par tweet en streaming

**RÃ©sultats qualitatifs :**
- âœ… Pipeline end-to-end fonctionnel
- âœ… Streaming temps rÃ©el opÃ©rationnel avec Kafka + Spark
- âœ… Interface web intuitive et rÃ©active
- âœ… Stockage persistant des prÃ©dictions
- âœ… Architecture conteneurisÃ©e et reproductible
- âœ… ScalabilitÃ© dÃ©montrÃ©e (traitement de 1000+ tweets)

**Exemples de prÃ©dictions rÃ©ussies :**
- "I love this product!" â†’ **Positive** (confidence: 0.92)
- "Terrible experience, very disappointed" â†’ **Negative** (confidence: 0.88)
- "The weather is cloudy today" â†’ **Neutral** (confidence: 0.79)

---

## ğŸ“„ Slide 15 â€“ Ã‰valuation et performances

**Titre:** MÃ©triques d'Ã‰valuation et Analyse des Performances

**MÃ©triques ML utilisÃ©es :**
- **Accuracy (PrÃ©cision globale) :** 86.64%
- **MÃ©trique d'Ã©valuation :** `MulticlassClassificationEvaluator`

**Optimisation des hyperparamÃ¨tres :**

**Logistic Regression - Grid Search :**
- `regParam` testÃ© : [0.1, 0.01] â†’ Optimal : **0.01**
- `elasticNetParam` testÃ© : [0.0, 0.5, 1.0] â†’ Optimal : **0.0**
- `maxIter` testÃ© : [10, 50, 100] â†’ Optimal : **10**

**Naive Bayes - Grid Search :**
- `smoothing` testÃ© : [0.0, 1.0, 2.0] â†’ Optimal : **1.0**

**Cross-Validation :**
- **K-Folds :** 3 folds pour LR, 5 folds pour NB
- **Avantage :** RÃ©duction de l'overfitting

**Performances systÃ¨me :**
- **Latence streaming :** < 1 seconde par batch
- **Throughput :** ~500 tweets/seconde (testÃ©)
- **Utilisation mÃ©moire :** 12GB allouÃ©s (Spark driver + executor)
- **Stockage MongoDB :** Insertion batch efficace

**Comparaison des modÃ¨les :**
- **Gagnant :** Logistic Regression (+4.13% accuracy vs Naive Bayes)
- **Trade-off :** LR lÃ©gÃ¨rement plus lent mais plus prÃ©cis

---

## ğŸ“„ Slide 16 â€“ DifficultÃ©s rencontrÃ©es

**Titre:** DÃ©fis Techniques et Solutions ApportÃ©es

**DifficultÃ©s majeures :**

**1. Gestion de la mÃ©moire Spark**
- **ProblÃ¨me :** OutOfMemory errors lors du traitement de gros datasets
- **Solution :** Configuration de `spark.executor.memory` et `spark.driver.memory` Ã  12GB

**2. Connexion Kafka-Spark**
- **ProblÃ¨me :** Erreurs de dÃ©pendances pour `spark-sql-kafka` connector
- **Solution :** Utilisation de `--packages` lors du spark-submit avec versions compatibles

**3. Streaming continu MongoDB**
- **ProblÃ¨me :** Change Stream nÃ©cessite replica set
- **Solution :** Configuration MongoDB en mode replica set (`rs0`) dans Docker

**4. PrÃ©traitement du texte**
- **ProblÃ¨me :** DonnÃ©es bruitÃ©es (emojis, URLs, caractÃ¨res spÃ©ciaux)
- **Solution :** Pipeline de nettoyage robuste avec regex et UDF Spark

**5. Latence temps rÃ©el**
- **ProblÃ¨me :** DÃ©lai entre production et affichage
- **Solution :** Optimisation du batch interval et utilisation de Server-Sent Events (SSE)

**6. ReproducibilitÃ© de l'environnement**
- **ProblÃ¨me :** DÃ©pendances multiples et conflits de versions
- **Solution :** Containerisation complÃ¨te avec Docker Compose

**7. Cross-Validation coÃ»teux**
- **ProblÃ¨me :** Temps d'entraÃ®nement long avec Grid Search
- **Solution :** RÃ©duction du nombre de folds et parallelisation Spark

---

## ğŸ“„ Slide 17 â€“ Perspectives et amÃ©liorations

**Titre:** Perspectives Futures et Axes d'AmÃ©lioration

**AmÃ©liorations court terme :**
1. **Connexion API X rÃ©elle** : IntÃ©grer l'API X v2 pour flux live authentiques
2. **ModÃ¨les avancÃ©s :** Tester BERT, RoBERTa, transformers pour NLP
3. **DÃ©tection de sarcasme :** Ajouter une couche d'analyse linguistique avancÃ©e
4. **Support multi-langues :** Ã‰tendre Ã  d'autres langues (franÃ§ais, arabe, espagnol)

**Optimisations techniques :**
5. **Dashboard analytics :** IntÃ©grer Grafana/Kibana pour visualisation avancÃ©e
6. **Alerting intelligent :** Notifications automatiques sur dÃ©tection de sentiment nÃ©gatif massif
7. **ScalabilitÃ© cloud :** DÃ©ploiement sur AWS/GCP/Azure avec auto-scaling

**Extensions fonctionnelles :**
8. **Analyse d'entitÃ©s nommÃ©es (NER) :** Identifier automatiquement les entitÃ©s mentionnÃ©es
9. **Topic modeling :** DÃ©tection automatique des sujets tendances
10. **Analyse des influenceurs :** Scoring de l'impact des utilisateurs

**Recherche et innovation :**
11. **ModÃ¨les hybrides :** Combiner rule-based et deep learning
12. **Analyse temporelle :** Ã‰volution du sentiment dans le temps
13. **PrÃ©diction de viralitÃ© :** Anticiper les tweets qui vont devenir viraux

**IntÃ©gration business :**
14. **API commerciale :** Exposer le service via API REST pour clients externes
15. **Reporting automatique :** GÃ©nÃ©ration de rapports PDF/Excel pÃ©riodiques

---

## ğŸ“„ Slide 18 â€“ DÃ©monstration

**Titre:** DÃ©monstration de l'Application

**FonctionnalitÃ©s dÃ©montrÃ©es :**

**1. Page d'accueil (`/`)**
- Saisie manuelle d'un tweet
- Bouton "Analyze Sentiment"
- Affichage instantanÃ© du rÃ©sultat et de la confiance

**2. Page de streaming (`/stream`)**
- Bouton "Start Streaming Tweets"
- Diffusion automatique depuis `X_validation.csv`
- Visualisation en temps rÃ©el des tweets et sentiments
- Mise Ã  jour dynamique sans rechargement (SSE)

**3. Page de validation (`/validation`)**
- Historique des 50 derniÃ¨res prÃ©dictions
- Tableau : Content | Sentiment | Confidence
- Tri anti-chronologique

**4. Architecture en action**
```
User Input â†’ Flask API â†’ Kafka Producer â†’ 
Spark Streaming â†’ ML Model â†’ MongoDB â†’ 
SSE Stream â†’ Frontend Update
```

**Liens de dÃ©monstration :**
- **Repository :** [GitHub](https://github.com/Bosaj/Real-Time_Sentiment_Analysis_on_X)

---

## ğŸ“„ Slide 19 â€“ Conclusion

**Titre:** Conclusion et Bilan du Projet

**Objectifs atteints âœ…**
- âœ… Pipeline complet d'analyse de sentiment en temps rÃ©el opÃ©rationnel
- âœ… ModÃ¨le ML avec 86.64% de prÃ©cision
- âœ… Architecture Big Data scalable (Kafka + Spark + MongoDB)
- âœ… Application web interactive et responsive
- âœ… Containerisation complÃ¨te avec Docker
- âœ… Documentation technique complÃ¨te

**CompÃ©tences acquises :**
- MaÃ®trise de l'Ã©cosystÃ¨me Apache (Kafka, Spark, Zookeeper)
- Expertise en NLP et classification de texte
- Architecture micro-services et streaming temps rÃ©el
- MLOps : entraÃ®nement, sauvegarde, dÃ©ploiement de modÃ¨les
- DevOps : Docker, orchestration de services

**Impact du projet :**
- ğŸ¯ Solution concrÃ¨te pour veille stratÃ©gique
- ğŸ¯ Base solide pour un produit commercial
- ğŸ¯ DÃ©monstration de compÃ©tences Big Data & IA

**Message final :**
Ce projet illustre parfaitement l'intÃ©gration de technologies Big Data modernes (Kafka, Spark) avec le Machine Learning pour rÃ©soudre une problÃ©matique rÃ©elle : comprendre l'opinion publique en temps rÃ©el. L'architecture mise en place est extensible et prÃªte pour une utilisation en production avec des amÃ©liorations futures.

---

## ğŸ“„ Slide 20 â€“ Questions & RÃ©ponses

**Titre:** Questions ?

**Sujets de discussion possibles :**

**Questions techniques :**
- Comment avez-vous gÃ©rÃ© les dÃ©pendances Spark-Kafka ?
- Pourquoi Logistic Regression plutÃ´t que Deep Learning ?
- Comment gÃ©rez-vous la scalabilitÃ© ?
- Quelle est la latence rÃ©elle du systÃ¨me ?

**Questions mÃ©tiers :**
- Quelles sont les applications concrÃ¨tes ?
- Comment amÃ©liorer la prÃ©cision du modÃ¨le ?
- Est-ce viable en production ?

**Architecture :**
- Pourquoi MongoDB plutÃ´t qu'une autre base ?
- Comment assurer la haute disponibilitÃ© ?

**AmÃ©liorations :**
- Quelles sont les prochaines Ã©tapes ?
- Comment intÃ©grer l'API X officielle ?

---

## ğŸ“„ Slide 21 â€“ Annexes

**Titre:** Annexes et Ressources

**RÃ©fÃ©rences :**
1. **Dataset :** Kaggle - X Entity Sentiment Analysis
2. **Documentation :** Apache Spark, Kafka, MongoDB
3. **Repository GitHub :** https://github.com/Bosaj/Real-Time_Sentiment_Analysis_on_X
4. **VidÃ©o dÃ©mo :** [Lien GitHub Assets]

**Technologies documentÃ©es :**
- Apache Kafka Documentation
- Spark Structured Streaming Guide
- Spark MLlib Guide
- Flask Documentation
- MongoDB Change Streams

**Commandes clÃ©s :**
```bash
# Lancer Kafka + MongoDB
docker-compose up -d

# Builder l'image Spark-Jupyter
docker build -t spark-jupyter:latest .

# EntraÃ®ner le modÃ¨le
spark-submit Spark-MLlib.py

# Lancer le streaming
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2 KafkaSpark-Streaming.py

# Lancer Flask
python Application-FLASK/main.py
```

---

**FIN DE LA PRÃ‰SENTATION**

*Merci pour votre attention !*
